\documentclass[11pt]{article}

\usepackage[english,greek]{babel}
\usepackage[utf8x]{inputenc}
\newcommand{\en}[1]{\textlatin{#1}}

\setlength\topmargin{-0.5in}
\setlength\textheight{23cm}
\setlength\oddsidemargin{-0.4in}
\setlength\textwidth{17cm}

\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{theorem}
\usepackage{graphicx}
\usepackage{pdfsync}
%\usepackage{showlabels}
\usepackage{bbm}

\theorembodyfont{\upshape}

\newtheorem{exercise}{Άσκηση}
\newtheorem{theorem}{Θεώρημα}
\newtheorem{example}{Παράδειγμα}
\newtheorem{corollary}{Πόρισμα}
\newtheorem{lemma}{Λήμμα}

\def\N{\mathbb{N}}
\def\Z{\mathbb{Z}}
\def\X{\mathbb{X}}
\def\P{\mathbb{P}}
\def\E{\mathbb{E}}
\def\R{\mathbb{R}}
\def\MX{{\cal M}(\X)}
\def\xn{\{X_n\}_{n\in\N_0}}
\def\beq{\begin{equation}}
\def\eeq{\end{equation}}
\def\bea{\begin{align}}
\def\ea{\end{align}}
\def\bea*{\begin{align*}}
\def\ea*{\end{align*}}
\def\CQFD{\hfill\hbox{\vrule\vbox to 8pt{\hrule width 8pt\vfill\hrule}\vrule}}
\def\half{\frac{1}{2}}
\def\IP{{\cal I}(P)}

\newcommand{\PP}[1]{\P\big[#1\big]}
\newcommand{\Px}[1]{\P_x\big[#1\big]}
\newcommand{\EE}[1]{\E\big[#1\big]}
\newcommand{\Ex}[1]{\E_x\big[#1\big]}

\begin{document}
\begin{center}
\Large {\bf KΕΦΑΛΑΙΟ \en{VI}. ΑΝΑΛΛΟΙΩΤΕΣ ΚΑΤΑΝΟΜΕΣ}
\end{center}
\noindent
\vspace{3mm}

\noindent
Οι αναλλοίωτες κατανομές είναι κατά κάποιο τρόπο οι φυσικές καταστάσεις μιας μαρκοβιανής αλυσίδας. 
Αν μια αλυσίδα ξεκινήσει από μια αναλλοίωτη κατανομή της θα παραμείνει σε αυτήν για πάντα, ενώ η ασυμπτωτική συμπεριφορά μιας αλυσίδας μπορεί να χαρακτηριστεί μέσω αυτών. Επίσης, οι απαντήσεις σε πολλά προβλήματα μπορούν εύκολα να εκφραστούν μέσω των αναλλοίωτων κατανομών. Σε αυτό το κεφάλαιο θα δούμε ικανές και αναγκαίες συνθήκες για την ύπαρξη αναλλοίωτων κατανομών, θα μελετήσουμε τις ιδιότητές και την δομή τους.
\section{Αναλλοίωτες κατανομές}\label{invdist}
Θα συμβολίζουμε το σύνολο των κατανομών στον $\X$ με $\MX$. Έτσι 
\[
\pi\in\MX\Leftrightarrow \text{ η } \pi \text{ είναι μια συνάρτηση }\pi:\X\to[0,1]\ \text{ με } \sum_{x\in\X}\pi(x)=1.
\]
\noindent
Έστω $\{X_n\}_{n\in\N}$ μια μαρκοβιανή αλυσίδα με αρχική κατανομή $\pi_0$ και πιθανότητες μετάβασης $\{p(x,y)\}_{x,y\in\X}$. Θα συμβολίζουμε την κατανομή της τυχαίας μεταβλητής $X_n$ με $\pi_n$, δηλαδή 
\beq
\pi_n(x)=\PP{X_n=x}\quad\text{για }x\in\X.
\label{mcd}
\eeq
Το κεντρικό ερώτημα αυτού του κεφαλαίου είναι αν η $\pi_n$ συγκλίνει καθώς $n\to\infty$, και αν ναι, ποιο είναι το όριό της $\pi$. \\[2mm]
{\bf Ορισμός} Αν $\{\pi_n\}_n$ είναι μια ακολουθία κατανομών στο $\MX$, θα λέμε ότι συγκλίνει στην κατανομή $\pi\in\MX$ αν και μόνο h πιθανότητα που αποδίδει η $\pi_n$ σε κάθε κατάσταση συγκλίνει στην αντίστοιχη πιθανότητα που αποδίδει η $\pi$. Δηλαδή,
\beq
\label{pwdef}
\pi_n\to\pi\in\MX\Leftrightarrow \pi_n(x)\to\pi(x)\quad\text{για κάθε }x\in\X
\eeq
{\bf Παρατήρηση:} Από ένα αποτέλεσμα της θεωρίας μέτρου, το λήμμα του \en{Scheff\'e} (βλ. \cite{DW}, παρ. 5.10), o παραπάνω ορισμός είναι ισοδύναμος με το φαινομενικά ισχυρότερο αποτέλεσμα
\beq
\label {l1def}
\pi_n\to\pi\in\MX\Leftrightarrow \sum_{x\in\X}|\pi_n(x)-\pi(x)|\to 0.
\eeq
{\bf Ορισμός:} Αν η $\{\pi_n\}_n$ είναι η ακολουθία των κατανομών μιας μαρκοβιανής αλυσίδας $\{X_n\}$, αν δηλαδή η $\pi_n$ ορίζεται όπως στην (\ref{mcd}) για κάθε $n\in\N_0$, και $\pi_n\to\pi\in\MX$, θα λέμε ότι η $\pi$ είναι η {\em κατανομή ισορροπίας} (ή εναλλακτικά η {\em ασυμπτωτική κατανομή}) της $\{X_n\}$.\\[2mm]
Το πρώτο μας αποτέλεσμα χαρακτηρίζει τις υποψήφιες κατανομές ισορροπίας μαρκοβιανών αλυσίδων.
 
\begin{theorem}
\label{invcond}
Αν η ακολουθία $\{\pi_n\}_n$ των κατανομών μιας μαρκοβιανής αλυσίδας $\{X_n\}_{n\in\N}$ με πίνακα πιθανοτήτων μετάβασης $P$ συγκλίνει στην κατανομή $\pi\in\MX$ τότε
\beq
\label{piP}
\pi=\pi P,\quad\text{δηλαδή}\quad \pi(x)=\sum_{y\in\X}\pi(y)p(y,x)\quad\text{για κάθε }x\in\X.
\eeq 
\end{theorem}
{\bf Απόδειξη:} Είδαμε στο δεύτερο κεφάλαιο ότι η κατανομή $\pi_n$ μιας μαρκοβιανής αλυσίδας $\{X_n\}_{n}$ μετά από $n$ βήματα, δηλαδή η κατανομή της τυχαίας μεταβλητής $X_n$, δίνεται από την 
\[
\pi_n=\pi_0P^n.
\]
Επομένως για κάθε $n\in\N$ έχουμε
\[
\pi_n=\pi_0(P^{n-1}P)=(\pi_0P^{n-1})P=\pi_{n-1}P,
\]
δηλαδή
\[
\pi_n(x)=\sum_{y\in\X}\pi_{n-1}(y)p(y,x)\quad\text{για κάθε }x\in\X.
\]
Παίρνοντας το όριο καθώς $n\to\infty$ στα δύο μέλη της προηγούμενης σχέσης το αριστερό μέλος συγκλίνει στην $\pi(x)$, ενώ για το δεξί μέλος έχουμε
\[
|\sum_{y\in\X}\pi_{n-1}(y)p(y,x)-\sum_{y\in\X}\pi(y)p(y,x)|\le\sum_{y\in\X}|\pi_{n-1}(x)-\pi(x)|p(y,x)\le\sum_{y\in\X}|\pi_{n-1}(x)-\pi(x)|\to 0,
\]
από την (\ref{l1def}). Επομένως $\pi(x)=\sum_{y\in\X}\pi(y)p(y,x)$ για κάθε $x\in X$.\CQFD\\

\noindent
Σύμφωνα με το προηγούμενο Θεώρημα τα μόνα υποψήφια όρια των κατανομών μιας μαρκοβιανής αλυσίδας με πίνακα πιθανοτήτων μετάβασης $P$ είναι εκείνες οι $\pi:\X\to[0,1]$ για τις οποίες
\beq
\label{pts}
\begin{cases}&\pi=\pi P\\ &\sum_{x\in\X}\pi(x)=1.\end{cases}
\eeq
{\bf Ορισμός:} Αν μια κατανομή $\pi\in\MX$ ικανοποιεί την (\ref{piP}) θα λέμε ότι είναι {\em αναλλοίωτη} (ή {\em στάσιμη}) κατανομή για την αλυσίδα $\{X_n\}_n$ με πίνακα πιθανοτήτων μετάβασης $P$.\\[2mm]
Το Θεώρημα \ref{invcond} μπορούμε να το αναδιατυπώσουμε και ως εξής. {\em Οι μόνες δυνατές κατανομές ισορροπίας μιας μαρκοβιανής αλυσίδας είναι οι αναλλοίωτες κατανομές της.} Η ορολογία αναλλοίωτη και στάσιμη εξηγείται από το παρακάτω Θεώρημα.
\begin{theorem}
\label{invariance}
Αν η αρχική κατανομή $\pi_0\in\MX$ μιας αλυσίδας στον $\X$ με πίνακα πιθανοτήτων μετάβασης $P$ ικανοποιεί την (\ref{piP}) τότε
\[
\pi_n=\pi_0\quad\text{για κάθε }n\in\N.
\]
Επιπλέον, η $\{X_n\}_{n\in\N_0}$ είναι στάσιμη, δηλαδή για κάθε $n,k\in\N_0$ και κάθε $x_0,x_1,\ldots,x_k\in\X$ έχουμε
\[
\PP{X_n=x_0,X_{n+1}=x_1,\ldots,X_{n+k}=x_k}=\PP{X_0=x_0,X_{1}=x_1,\ldots,X_{k}=x_k}.
\]
{\bf Απόδειξη:} Θα δείξουμε τον ισχυρισμό $\pi_n=\pi_0$ για κάθε $n\in\N$ επαγωγικά. Για $n=1$ έχουμε
\[
\pi_1=\pi_0P=\pi_0,\quad
\]
μια και για την $\pi_0$ έχουμε υποθέσει ότι ικανοποιεί την (\ref{piP}). Έστω τώρα ότι για κάποιο $n\in\N$ έχουμε $\pi_n=\pi_0$. Τότε
\[
\pi_{n+1}=\pi_nP=\pi_0P=\pi_0.
\]
Επομένως $\pi_n=\pi_0$ για κάθε $n\in\N$. Για τον δεύτερο ισχυρισμό έχουμε από την μαρκοβιανή ιδιότητα
\begin{align*}
\PP{X_n=x_0,\ldots,X_{n+k}=x_k}&=\PP{X_n=x_0}\PP{X_{n+1}=x_1\,|\,X_n=x_0}\cdots\PP{X_{n+k}=x_k\,|\,X_{n+k-1}=x_{k-1}}\\
&=\pi_n(x_0)p(x_0,x_1)\cdots p(x_{k-1},x_k)\\
&=\pi_0(x_0)p(x_0,x_1)\cdots p(x_{k-1},x_k)\\
&=\PP{X_0=x_0,X_{1}=x_1,\ldots,X_{k}=x_k}.
\end{align*}
\CQFD\\
\end{theorem}
\begin{example}
Έστω $\{X_n\}_n$  μια μαρκοβιανή αλυσίδα σε έναν χώρο με δύο καταστάσεις $\X=\{\alpha,\beta\}$ και πίνακα πιθανοτήτων μετάβασης
\[
{P}=\bordermatrix{&&\cr
&1-p&p\cr
&q&1-q\cr
},
\]
με $p,q\in(0,1)$. Από την (\ref{pts}) προκειμένου η $\pi=(\pi_\alpha,\pi_\beta)$ να είναι αναλλοίωτη κατανομή της αλυσίδας θα πρέπει να ικανοποιεί τις
\[
\begin{cases}&\pi_a=(1-p)\pi_\alpha+q\pi_\beta\\ &\pi_\beta=p\pi_\alpha+(1-q)\pi_\beta\\&\pi_\alpha+\pi_\beta=1.\end{cases}
\]
Λύνοντας το παραπάνω σύστημα βρίσκουμε ότι η
\[
\pi=\big(\frac{q}{p+q},\frac{p}{p+q}\big)
\]
είναι αναλλοίωτη κατανομή της αλυσίδας. Επομένως αν η αρχική κατανομή της αλυσίδας είναι η $\pi$, αν δηλαδή
\[
\PP{X_0=\alpha}=\frac{q}{p+q}\quad\text{και}\quad\PP{X_0=\beta}=\frac{p}{p+q}
\]
τότε $\pi_n=\pi$ για κάθε $n\in\N$. Προσέξτε ότι σε κάθε της βήμα η αλυσίδα αλλάζει κατάσταση με πιθανότητα $p$ αν βρίσκεται στην κατάσταση $\alpha$ ή $q$ αν βρίσκεται στην κατάσταση $\beta$. Αυτό που δεν αλλάζει είναι η κατανομή της $X_n$, δηλαδή η πιθανότητα να βρούμε την αλυσίδα σε καθεμιά από τις δύο καταστάσεις.
\end{example}
\section{Η δομή του $\IP$}
Στην συνέχεια θα εξετάσουμε αν μπορούμε να βρούμε αναλλοίωτες κατανομές για μια αλυσίδα, και στην περίπτωση που μπορούμε ποιες είναι αυτές. Θα συμβολίζουμε με $\IP$ το σύνολο των αναλλοίωτων κατανομών μιας αλυσίδας με πίνακα πιθανοτήτων μετάβασης $P$, δηλαδή
\[
\IP=\{\pi\in\MX: \pi=\pi P\}.
\]
Το επόμενο λήμμα θα μας φανεί πολύ χρήσιμο
\begin{lemma}
\label{idcomparison}
Αν $\xn$ είναι μια μαρκοβιανή αλυσίδα με πίνακα πιθανοτήτων μετάβασης $P$ και $\pi\in\IP$ τότε για κάθε $x,y\in\X$ έχουμε
\beq
\pi(y)\ge\pi(x)\ \E_x\Big[\sum_{k=1}^{T_x^+}\mathbbm{1}\{X_k=y\}\Big].
\label{compleq}
\eeq
\end{lemma}
{\bf Απόδειξη:} Έστω $\pi\in\IP$. Για κάθε $x,y\in\X$ έχουμε
\begin{align*}
\pi(y)&=\sum_{z\in\X}\pi(z)p(z,y)=\pi(x)p(x,y)+\sum_{z\neq x}\pi(z)p(z,y)\\
&=\pi(x)p(x,y)+\sum_{z\neq x}\Big(\sum_{u\in\X}\pi(u)p(u,z)\Big)p(z,y)\\
&=\pi(x)\Big(p(x,y)+\sum_{z\neq x}p(x,z)p(z,y)\Big)+\sum_{z,u\neq x}\pi(u)p(u,z)p(z,y)
\end{align*}
Aς επαναλάβουμε την παραπάνω διαδικασία ακόμα μια φορά, γράφοντας
\[
\pi(u)=\sum_{w\in\X}\pi(w)p(w,u)=\pi(x)p(x,u)+\sum_{w\neq x}\pi(w)p(w,u).
\]
Παίρνουμε τότε ότι
\begin{align}
\pi(y)&=\pi(x)\Big(p(x,y)+\sum_{z\neq x}p(x,z)p(z,y)+\sum_{z,u\neq x}p(x,u)p(u,z)p(z,y)\Big)\notag\\&\quad+\sum_{z,u,w\neq x}\pi(w)p(w,u)p(u,z)p(z,y).
%&=\pi(x)\Big(\sum_{k=1}^3\Px{X_k=y,\ T_x^+\ge k}\Big)+\sum_{z,u,w\neq x}\pi(w)p(w,u)p(u,z)p(z,y).
\label{iter3}
\end{align}
Προσέξτε ότι στον όρο $\sum_{z,u\neq x}p(x,u)p(u,z)p(z,y)$ αθροίζουμε τις πιθανότητες όλων των μονοπατιών μήκους 3 που ξεκινούν από το $x$ και καταλήγουν στο $y$ χωρίς ενδιάμεσα να έχουν ξαναπεράσει από το $x$. Άρα,
\[
\sum_{z,u\neq x}p(x,u)p(u,z)p(z,y)=\Px{X_1\neq x,\ X_2\neq x,\ X_3=y}=\Px{X_3=y,\ T_x^+\ge 3}.
\]
Αντίστοιχα έχουμε
\[
\sum_{z\neq x}p(x,z)p(z,y)=\Px{X_1\neq x,\ X_2=y}=\Px{X_2=y,\ T_x^+\ge 2}
\]
ενώ
\[
p(x,y)=\Px{X_1=y}=\Px{X_1=y,\ T_x^+\ge 1}.
\]
Με αυτήν παρατήρηση μπορούμε να ξαναγράψουμε την (\ref{iter3}) ως
\[
\pi(y)=\pi(x)\Big(\sum_{k=1}^3\Px{X_k=y,\ T_x^+\ge k}\Big)+\sum_{z,u,w\neq x}\pi(w)p(w,u)p(u,z)p(z,y).
\]
Θα πρέπει να είναι τώρα φανερό ότι αν επαναλάβουμε αυτήν την διαδικασία $n$ φορές έχουμε ότι
\begin{align}
\pi(y)&=\pi(x)\Big(\sum_{k=1}^n\Px{X_k=y,\ T_x^+\ge k}\Big)+\sum_{x_1,\ldots,x_n\neq x}\pi(x_1)p(x_1,x_2)\cdots p(x_n,y)\label{prelimit}\\
&\ge\pi(x) \Big(\sum_{k=1}^n\Px{X_k=y,\ T_x^+\ge k}\Big)\qquad\text{για κάθε }n\in\N.\notag
\end{align}
Περνώντας στο όριο $n\to\infty$ έχουμε λοιπόν
\begin{align*}
\pi(y)&\ge \pi(x) \Big(\sum_{k=1}^\infty\Px{X_k=y,\ T_x^+\ge k}\Big)\\
&=\pi(x)\  \Big(\sum_{k=1}^\infty\Ex{\mathbbm{1}\{X_k=y,\ T_x^+\ge k\}}\Big).
\end{align*}
Εφόσον οι δείκτριες συναρτήσεις που εμφανίζονται παραπάνω είναι μη αρνητικές, από το θεώρημα \en{Fubini-Tonelli} μπορούμε να εναλλάξουμε την άθροιση ως προς $k$ και την αναμενόμενη τιμή, παίρνοντας
\begin{align*}
\pi(y)&\ge\pi(x)\ \E_x\Big[\sum_{k=1}^\infty\mathbbm{1}\{X_k=y,\ T_x^+\ge k\}\Big]\\
&=\pi(x)\ \E_x\Big[\sum_{k=1}^{T_x^+}\mathbbm{1}\{X_k=y\}\Big].\
\end{align*}
\CQFD\\
\ \\
{\bf Ορισμός:} Θα λέμε μια κατάσταση $x\in\X$ {\em γνησίως επαναληπτική} αν $\Ex{T_x^+}<+\infty$.\\
\ \\
Η γνήσια επαναληπτικότητα είναι μια έννοια ισχυρότερη της επαναληπτικότητας, αφού αν $\Ex{T_x^+}<+\infty$ τότε αναγκαστικά έχουμε $\Px{T_x^+<\infty}=1$, και άρα η $x$ είναι επαναληπτική. Το ακόλουθο Πόρισμα μας εγγυάται ότι οποιαδήποτε αναλλοίωτη κατανομή μιας αλυσίδας στηρίζεται σε γνησίως επαναληπτικές καταστάσεις.
\begin{corollary}\label{support}
Αν $\pi\in\IP$ και $x\in\X$ τότε 
\[
\Ex{T_x^+}=+\infty\Rightarrow \pi(x)=0.
\]
\end{corollary}
{\bf Απόδειξη:} Αθροίζοντας τις ανισότητες (\ref{compleq}) για όλα τα $y\in\X$ έχουμε
\[
1=\sum_{y\in\X}\pi(y)\ge \pi(x)\ \sum_{y\in\X}\E_x\Big[\sum_{k=1}^{T_x^+}\mathbbm{1}\{X_k=y\}\Big]=\pi(x)\ \E_x\Big[\sum_{k=1}^{T_x^+}\sum_{y\in\X}\mathbbm{1}\{X_k=y\}\Big],
\]
όπου χρησιμοποιήσαμε το θεώρημα \en{Fubini-Tonelli} για να εναλλάξουμε την σειρά των αθροίσεων και της αναμενόμενης τιμής.
Προσέξτε όμως ότι στο άθροισμα ως προς $y$ υπάρχει ακριβώς ένας όρος $\mathbbm{1}\{X_k=y\}$ που είναι ίσος με 1 (αυτός που αντιστοιχεί στην κατάσταση της $X_k$ ) ενώ όλοι οι υπόλοιποι είναι μηδέν. Επομένως, η παραπάνω ανισότητα γίνεται
\[
1\ge \pi(x)\ \E_x\Big[\sum_{k=1}^{T_x^+}1\Big]=\pi(x)\ \Ex{T_x^+},
\]
απ' όπου έπεται ο ισχυρισμός μας. \CQFD\ \\
\begin{corollary}\label{prexist}
Αν μια μαρκοβιανή αλυσίδα έχει αναλλοίωτη κατανομή τότε έχει τουλάχιστον μία γνησίως επαναληπτική κατάσταση. 
\end{corollary}
{\bf Απόδειξη:} Αν $\pi\in\IP$ τότε $\pi(y)\ge 0$ για κάθε $y\in\X$ και $\sum_{y\in\X}\pi(y)=1$. Θα υπάρχει επομένως κάποια κατάσταση $x$ για την οποία $\pi(x)>0$ και άρα από το Πόρισμα \ref{support} θα πρέπει $\Ex{T_x^+}<\infty.$\CQFD\\
\ \\
Στο επόμενο θεώρημα θα δείξουμε ότι και το αντίστροφο του προηγούμενου πορίσματος είναι σωστό. Δηλαδή, αν μια αλυσίδα έχει μια γνησίως επαναληπτική κατάσταση $x$ τότε έχει και αναλλοίωτη κατανομή, κατασκευάζοντας μια εκπεφρασμένα. Η ιδέα προέρχεται από το Λήμμα \ref{idcomparison}.
\begin{theorem}\label{explicit}
Έστω $x\in\X$ μια γνησίως επαναληπτική κατάσταση. Ορίζουμε
\[
\pi_x(y)=\frac{1}{\Ex{T_x^+}}\E_x\Big[\sum_{k=1}^{T_x^+}\mathbbm{1}\{X_k=y\}\Big]
\] 
H $\pi_x$ είναι αναλλοίωτη κατανομή της αλυσίδας $\xn$, και 
\beq
\pi_x(x)=\frac{1}{\Ex{T_x^+}}.
\label{invtime}
\eeq
\end{theorem}
{\bf Παρατήρηση:} Μπορούμε να σκεφτούμε την κατανομή $\pi_x$ ως εξής. Ξεκινώντας από την $x$ κάνουμε μια εκδρομή μέχρι να επιστρέψουμε πάλι στην κατάσταση $x$, δηλαδή μέχρι τον χρόνο διακοπής $T_x^+$. Κατά την διάρκεια αυτής της εκδρομής σημειώνουμε πόσες επισκέψεις κάναμε στην κατάσταση $y\in\X$. Το πλήθος αυτών των επισκέψεων είναι
\[
\sum_{k=1}^{T_x^+}\mathbbm{1}\{X_k=y\}
\]
και είναι βέβαια μια τυχαία μεταβλητή. Το βάρος που δίνει η $\pi_x$ στην κατάσταση $y$ είναι ανάλογο προς το αναμενόμενο πλήθος τον επισκέψεων μας στην κατάσταση $y$ κατά τη διάρκεια αυτής της εκδρομής γύρω από την $x$. Η σταθερά αναλογίας $\frac{1}{\Ex{T_x^+}}$ που εμφανίζεται είναι απλά ένας παράγοντας κανονικοποίησης ώστε η $\pi_x$ να είναι κατανομή. \\
\ \\
{\bf Απόδειξη:} Ας δούμε πρώτα ότι $\pi_x\in\MX.$ Πράγματι, είναι φανερό από τον ορισμό ότι $\pi_x(y)\ge 0$ για κάθε $y\in\X$,  ενώ
\[
\sum_{y\in\X}\pi_x(y)= \frac{1}{\Ex{T_x^+}}\ \sum_{y\in\X}\E_x\Big[\sum_{k=1}^{T_x^+}\mathbbm{1}\{X_k=y\}\Big]= \frac{1}{\Ex{T_x^+}}\ \E_x\Big[\sum_{k=1}^{T_x^+}\sum_{y\in\X}\mathbbm{1}\{X_k=y\}\Big]= \frac{\Ex{T_x^+}}{\Ex{T_x^+}}=1.
\]
Ο ισχυρισμός της (\ref{invtime}) προκύπτει άμεσα από τον ορισμό του χρόνου $T_x^+=\inf\{k\ge 1: X_k=x\}$, αφού κατά την διάρκεια της εκδρομής γύρω από την $x$, δηλαδή για $k\in\{1,2,\ldots,T_x^+\}$ η αλυσίδα μας βρίσκεται στην $x$ μόνο την χρονική στιγμή $T_x^+$.\\
\ \\
Θα δείξουμε τώρα ότι η $\pi_x$ είναι αναλλοίωτη. Πράγματι, για κάθε $y\in\X$ έχουμε
\begin{align}
\pi_x(y)&=\pi_x(x)\ \E_x\Big[\sum_{k=1}^{T_x^+}\mathbbm{1}\{X_k=y\}\Big]\notag\\
&=\pi_x(x)\ \E_x\Big[\sum_{k=1}^{\infty}\mathbbm{1}\{X_k=y,\ T_x^+\ge k\}\Big]\notag\\
&=\pi_x(x)\ \E_x\Big[\sum_{k=1}^{\infty}\sum_{z\in\X}\mathbbm{1}\{X_{k-1}=z,\ X_k=y,\ T_x^+\ge k\}\Big]\notag\\
&=\pi_x(x)\ \sum_{z\in\X}\sum_{k=1}^{\infty}\ \E_x\Big[\mathbbm{1}\{X_{k-1}=z,\ X_k=y,\ T_x^+\ge k\}\Big] \quad \text{(θ. \en{Fubini-Tonelli)}}\notag\\
&=\pi_x(x)\ \sum_{z\in\X}\sum_{k=1}^{\infty}\ \Px{X_{k-1}=z,\ X_k=y,\ T_x^+\ge k}\label{step1}
\end{align}
Παρατηρήστε τώρα ότι $\mathbbm{1}\{T_x^+\ge k\}=\mathbbm{1}\{X_1\neq x,\ X_2\neq x,\cdots,X_{k-1}\neq x\}$,
επομένως το ενδεχόμενο $\{T_x^+\ge k\}$ ανήκει στην κλάση ${\cal F}_{k-1}$. Έτσι, από την μαρκοβιανή ιδιότητα έχουμε
\[
\Px{X_k=y\, |\, X_{k-1}=z,\, T_x^+\ge k}=\Px{X_k=y\, |\, X_{k-1}=z}=p(z,y),
\]
και η σχέση (\ref{step1}) γίνεται
\begin{align}
\pi_x(y)&=\pi_x(x)\ \sum_{z\in\X}p(z,y)\sum_{k=1}^{\infty}\Px{X_{k-1}=z,\, T_x^+\ge k}\notag\\
&=\pi_x(x)\ \sum_{z\in\X}p(z,y)\sum_{k=1}^{\infty}\Ex{\mathbbm{1}\{X_{k-1}=z,\, T_x^+\ge k\}}\notag\\
&=\pi_x(x)\ \sum_{z\in\X}p(z,y)\ \E_x\Big[\sum_{k=1}^{\infty}\mathbbm{1}\{X_{k-1}=z,\, T_x^+\ge k\}\Big]\quad \text{(θ. \en{Fubini-Tonelli)}}\notag\\
&=\pi_x(x)\ \sum_{z\in\X}p(z,y)\ \E_x\Big[\sum_{k=1}^{T_x^+}\mathbbm{1}\{X_{k-1}=z\}\Big].\label{step2}
\end{align}
Παρατηρήστε τέλος ότι
\[
\E_x\Big[\sum_{k=1}^{T_x^+}\mathbbm{1}\{X_{k-1}=z\}\Big]\stackrel{m=k-1}{=}\E_x\Big[\sum_{m=0}^{T_x^+-1}\mathbbm{1}\{X_{m}=z\}\Big]=\E_x\Big[\sum_{m=1}^{T_x^+}\mathbbm{1}\{X_{m}=z\}\Big],
\]
όπου η τελευταία ισότητα προκύπτει γιατί η αλυσίδα μας με $\P_x$-πιθανότητα 1 βρίσκεται στην $x$ τόσο την χρονική στιγμή 0 όσο και την χρονική στιγμή $T_x^+$. Έτσι, η (\ref{step2}) γίνεται 
\[
\pi_x(y)=\sum_{z\in\X}p(z,y)\pi_x(x)\ \E_x\Big[\sum_{m=1}^{T_x^+}\mathbbm{1}\{X_{m}=z\}\Big]=\sum_{z\in\X}p(z,y)\pi_x(z),
\]
και επομένως $\pi_x\in\IP$.\CQFD\\
\ \\
Όπως είδαμε μια γνησίως επαναληπτική κατάσταση $x\in\X$ είναι επαναληπτική και άρα ανήκει αναγκαστικά σε μια κλειστή κλάση $C_x$. Από την κατασκευή της κατανομής $\pi_x$ είναι φανερό ότι 
\[
y\notin{C}_x\Rightarrow \pi_x(y)=0,
\]
αφού αν $y\notin{C}_x$ η αλυσίδα που ξεκινά από το $x$ αποκλείεται να επισκεφτεί την κατάσταση $y$ ποτέ, και ειδικώτερα αποκλείεται να επισκεφτεί την $y$ μέχρι να επιστρέψει στην $x$. Θα δείξουμε τώρα ότι η $\pi_x$ δίνει θετικό βάρος σε όλες τις καταστάσεις της κλάσης ${C}_x$.
\begin{theorem}\label{positiveweight}
Αν η κατάσταση $x$ είναι γνησίως επαναληπτική και $y\in{C}_x$ τότε $\pi_x(y)>0$.
\end{theorem}
{\bf Απόδειξη:} Εφόσον η $y$ είναι προσβάσιμη από την $x$ υπάρχει $m\in\N$ τέτοιο ώστε $p^{(m)}(x,y)>0$. Επίσης εύκολα μπορούμε να δείξουμε επαγωγικά ότι
\[
\pi_x\in\IP\Rightarrow \pi_x=\pi_x P\Rightarrow \pi_x=\pi_xP^m.
\]
Επομένως
\[
\pi_x(y)=\sum_{z\in\X}\pi_x(z)p^{(m)}(z,y)\ge \pi_x(x)p^{(m)}(x,y)>0.
\]
\begin{corollary}\label{precclass}
H γνήσια επαναληπτικότητα είναι ιδιότητα κλάσης, δηλαδή αν η κατάσταση $x$ είναι γνησίως επαναληπτική και $y\in{C}_x$ τότε και η $y$ είναι γνησίως επαναληπτική.
\end{corollary}
{\bf Απόδειξη:} Προκύπτει αμέσως από το Πόρισμα \ref{support} αφού
\[
\pi_x\in\IP \quad\text{και}\quad \pi_x(y)>0\ \Rightarrow\  \E_y\big[T_y^+\big]<+\infty.
\]
\CQFD\\
Με βάση το παραπάνω Πόρισμα έχει νόημα να κάνουμε λόγο για γνησίως επαναληπτικές κλάσεις. Σημειώστε ότι εφόσον οι ανοιχτές κλάσεις μιας αλυσίδας είναι παροδικές τότε κάθε γνησίως επαναληπτική κλάση είναι κλειστή. Το ακόλουθο Πόρισμα 
συνοψίζει μια ικανή και αναγκαία συνθήκη για το πότε μια κλειστή κλάση είναι γνησίως επαναληπτική και είναι συχνά ένας εύκολος τρόπος να αποδείξει κανείς την γνήσια επαναληπτικότητα μιας κλειστής κλάσης. Σημειώστε ότι για τον σκοπό αυτό αρκεί να περιορίσουμε την αλυσίδα σε αυτήν την κλειστή κλάση, οπότε η αλυσίδα που θα προκύψει θα είναι μη υποβιβάσιμη. 
\begin{corollary}\label{nsPR}
Μια μη υποβιβάσιμη μαρκοβιανή αλυσίδα είναι γνησίως επαναληπτική αν και μόνο αν έχει αναλλοίωτη κατανομή.
\end{corollary}
{\bf Απόδειξη:} Το Θεώρημα \ref{explicit} μας εξασφαλίζει την ύπαρξη μιας αναλλοίωτης κατανομής $\pi_x$ αν υπάρχει μια επαναληπτική κατάσταση $x$. Αντίστροφα, αν η αλυσίδα έχει αναλλοίωτη κατανομή $\pi$ τότε από το Πόρισμα \ref{prexist} η αλυσίδα θα έχει μια γνησίως επαναληπτική κατάσταση. Εφόσον η αλυσίδα είναι μη υποβιβάσιμη, από το Πόρισμα \ref{precclass} όλες οι καταστάσεις της θα είναι γνησίως επαναληπτικές.\CQFD
\begin{corollary}\label{finir}
Μια μη υποβιβάσιμη μαρκοβιανή αλυσίδα σ' έναν πεπερασμένο χώρο καταστάσεων είναι γνησίως επαναληπτική.
\end{corollary}
{\bf Απόδειξη:} Θεωρούμε ένα $x\in\X$, και ορίζουμε $T_x^+=\inf\{k>0: X_k=x\}$ τον χρόνο πρώτης επιστροφής στην κατάσταση $x$. Εφόσον η αλυσίδα είναι μη υποβιβάσιμη ολόκληρος ο $\X$ είναι μια κλειστή και πεπερασμένη, και άρα επαναληπτική κλάση. Έτσι, $\Px{T_x^+<\infty}=1$. Ορίζουμε την $\lambda:\X\to[0,\infty]$ με 
\[
\lambda(y)=\ \E_x\Big[\sum_{k=1}^{T_x^+}\mathbbm{1}\{X_k=y\}\Big],
\]
Από την απόδειξη του Θεωρήματος \ref{explicit} έχουμε ότι $\lambda=\lambda P$, ενώ $\lambda(x)=1$. Θα δείξουμε ότι $\lambda(y)<\infty$ για κάθε $y\in\X$. Εφόσον η $x$ είναι προσβάσιμη από την $y$ επιλέγουμε $m\in\N$ τέτοιο ώστε $p^{(m)}(y,x)>0$. Έτσι
\[
1=\lambda(x)=\sum_{z\in\X} \pi(z)p^{(m)}(z,x)\ge \lambda(y)p^{(m)}(y,x)\Rightarrow \lambda(y)<\frac{1}{p^{(m)}(y,x)}<+\infty.
\]
Αν ορίσουμε τώρα $Z=\sum_{y\in\X}\lambda(y)\in(1,+\infty)$, και $\pi(y)=\lambda(y)/Z$ για κάθε $y\in\X$, εύκολα επιβεβαιώνουμε ότι $\pi\in\IP$ και άρα από το Πόρισμα \ref{nsPR} η αλυσίδα είναι γνησίως επαναληπτική.\CQFD\\
\ \\
Έχουμε ως τώρα δει ότι οποιαδήποτε αναλλοίωτη κατανομή δίνει μηδενικό βάρος σε κλάσεις που δεν είναι γνησίως επαναληπτικές (Πόρισμα \ref{support}), ενώ για κάθε γνησίως επαναληπτική κλάση έχουμε κατασκευάσει μια αναλλοίωτη κατανομή $\pi_x$ που στηρίζεται στις καταστάσεις αυτής της κλάσης (Θεωρήματα \ref{explicit} και \ref{positiveweight}.) Θα δείξουμε στην συνέχεια ότι η αναλλοίωτη κατανομή που στηρίζεται σε μια γνησίως επαναληπτική κλάση είναι μοναδική. Όπως και στο προηγούμενο Πόρισμα, περιορίζοντας την αλυσίδα σε μια γνησίως επαναληπτική, και επομένως κλειστή κλάση, αρκεί να υποθέσουμε ότι η αλυσίδα μας είναι μη υποβιβάσιμη.
\begin{theorem}\label{uniqueinv}
Αν η $\xn$ είναι μια μη υποβιβάσιμη γνησίως επαναληπτική αλυσίδα τότε έχει μοναδική αναλλοίωτη κατανομή.
\end{theorem}
{\bf Απόδειξη:} H ύπαρξη μιας τουλάχιστον αναλλοίωτης κατανομής εξασφαλίζεται από το Θεώρημα \ref{explicit}. Θα αποδείξουμε εδώ την μοναδικότητα. Έστω λοιπόν $\pi$ μια αναλλοίωτη κατανομή της $\xn$. \\
\ \\
Θεωρούμε ένα $x\in\X$ και ορίζουμε την αναλλοίωτη κατανομή $\pi_x$ όπως στο Θεώρημα \ref{explicit}. Θα δείξουμε ότι $\pi(y)=\pi_x(y)$ για κάθε κατάσταση $y\in\X$. Εφόσον η αλυσίδα είναι μη υποβιβάσιμη η $x$ θα είναι προσβάσιμη από την $y$. Υπάρχει επομένως $m\in\N$ τέτοιο ώστε $p^{(m)}(y,x)>0$. Έχουμε τώρα
\begin{align*}
0&=\pi(x)-\pi(x)=\pi(x)-\frac{\pi(x)}{\pi_x(x)}\pi_x(x)\\
&=\sum_{z\in\X}\pi(z)p^{(m)}(z,x)-\frac{\pi(x)}{\pi_x(x)}\sum_{z\in\X}\pi_x(z)p^{(m)}(z,x)\quad (\pi,\pi_x\in\IP)\\
&=\sum_{z\in\X}\Big(\pi(z)-\pi(x)\frac{\pi_x(z)}{\pi_x(x)}\Big)p^{(m)}(z,x).
\end{align*}
Από το Λήμμα \ref{idcomparison} κάθε προσθετέος στο παραπάνω άθροισμα είναι μεγαλύτερος ή ίσος του μηδενός. Για να είναι το άθροισμα 0 θα πρέπει όλοι οι προσθετέοι να είναι ίσοι με 0. Ειδικώτερα,
\[
\Big(\pi(y)-\frac{\pi_x(y)}{\pi_x(x)}\pi(x)\Big)p^{(m)}(y,x)=0\Rightarrow \pi(y)=\frac{\pi(x)}{\pi_x(x)}\pi_x(y).
\]
Εφόσον η $y$ είναι αυθαίρετα επιλεγμένη έχουμε ότι
\beq
\pi(y)=\frac{\pi(x)}{\pi_x(x)}\pi_x(y) \quad\text{για κάθε }y\in\X.
\label{com1}
\eeq
Αθροίζοντας τις παραπάνω σχέσεις σε όλα τα $y\in\X$ έχουμε
\[
1=\sum_{y\in\X}\pi(y)=\sum_{y\in\X}\frac{\pi(x)}{\pi_x(x)}\pi_x(y)=\frac{\pi(x)}{\pi_x(x)},
\]
και άρα η (\ref{com1}) γίνεται $\pi(y)=\pi_x(y)$ για κάθε $y\in\X$.\CQFD\\
\ \\
\noindent
{\bf Παρατήρηση:} Μια άμεση συνέπεια του Θεωρήματος \ref{uniqueinv} είναι ότι αν οι καταστάσεις $x,y$ ανήκουν σε μια γνησίως επαναληπτική κλάση ${C}$ τότε $\pi_x\equiv\pi_y$. Έχει λοιπόν νόημα να μιλάμε για την μοναδική αναλλοίωτη κατανομή $\pi_{C}$ που αντιστοιχεί στην κλάση ${C}$. Το τελικό συμπέρασμα αυτής της παραγράφου είναι ότι κάθε αναλλοίωτη κατανομή 
είναι ένας κυρτός συνδυασμός τέτοιων κατανομών.
\begin{theorem}
Έστω ${\cal R}$ το σύνολο των γνησίως επαναληπτικών κλάσεων μιας μαρκοβιανής αλυσίδας $\xn$ με πίνακα πιθανοτήτων μετάβασης $P$. Τότε 
\[
\IP=co\{\pi_{C}: {C}\in{\cal R}\}\equiv\big\{\sum_{C\in{\cal R}}\alpha(C)\pi_C:\ \alpha(C)\ge 0\ \forall C\in{\cal R}, \text{ και } \sum_{C\in{\cal R}}\alpha(C)=1\big\}.
\]
\end{theorem}
{\bf Απόδειξη:} Ας υποθέσουμε πρώτα ότι $\pi=\sum_{C\in{\cal R}}\alpha(C)\pi_C$ με $\alpha(C)\ge 0$ και $\sum_{C\in{\cal R}}\alpha(C)=1$. Είναι φανερό ότι $\pi(x)\ge 0$ για κάθε $x\in\X$ ενώ
\[
\sum_{x\in\X}\pi(x)=\sum_{x\in\X}\sum_{C\in{\cal R}}\alpha(C)\pi_C(x)=\sum_{C\in{\cal R}}\alpha(C)\sum_{x\in\X}\pi_C(x)=\sum_{C\in{\cal R}}\alpha(C)=1.
\]
Επομένως $\pi\in\MX$. Για να δείξουμε ότι $\pi\in\IP$ και άρα $co\{\pi_{C}: {C}\in{\cal R}\}\subset\IP$ παρατηρούμε ότι
\[
\pi P=\Big(\sum_{C\in{\cal R}}\alpha(C)\pi_C\Big)P=\sum_{C\in{\cal R}}\alpha(C)(\pi_CP)=\sum_{C\in{\cal R}}\alpha(C)\pi_C=\pi.
\]
Θα δείξουμε τώρα ότι $\IP\subset co\{\pi_{C}: {C}\in{\cal R}\}$. Για $\mu\in\IP$ και $C\in{\cal R}$ τέτοια ώστε $\mu[C]>0$ θεωρούμε τον περιορισμό $\left.\mu\right|_C$ του $\mu$ στην κλάση $C$. Συγκεκριμένα, για κάθε $A\subset\X$ έχουμε
\[
\left.\mu\right|_C\big[A\big]=\mu\big[A\,|\,C\big]=\frac{\mu\big[A\cap C\big]}{\mu\big[C\big]}.
\]
Θα δείξουμε ότι $\left.\mu\right|_C=\pi_C$. Η $\left.\mu\right|_C$ είναι μια κατανομή που στηρίζεται στην κλειστή κλάση $C$ και από το Θεώρημα \ref{uniqueinv} για να την ταυτίσουμε με την $\pi_C$ αρκεί να δείξουμε ότι είναι αναλλοίωτη. Πράγματι, για κάθε $x\in C$ έχουμε $p(y,x)=0$ για κάθε $y\notin C$ και άρα
\[
\left.\mu\right|_C(x)=\frac{\mu(x)}{\mu\big[C\big]}=\frac{1}{\mu\big[C\big]}\sum_{y\in\X}\mu(y)p(y,x)=\sum_{y\in C}\frac{\mu(y)}{\mu\big[C\big]}p(y,x)=\sum_{y\in C}\left.\mu\right|_C(y)p(y,x).
\]
Δείξαμε λοιπόν ότι αν $\mu\big[C\big]>0$ τότε $\left.\mu\right|_C\equiv\pi_C$. Αν $\mu\big[C\big]=0$ ορίζουμε $\left.\mu\right|_C=\pi_C$. Από το Πόρισμα \ref{support} έχουμε ότι
\[
\mu\big[\bigcup_{C\in{\cal R}}C\big] = 1.
\]
Έτσι, για κάθε $A\subset\X$
\[
\mu\big[A\big]=\mu\Big[\bigcup_{C\in{\cal R}}(A\cap C)\Big]=\sum_{C\in{\cal R}}\mu\big[A\cap C]=\sum_{C\in{\cal R}}\mu\big[C\big]\left.\mu\right|_C\big[A\big]=\sum_{C\in{\cal R}}\mu\big[C\big]\pi_C\big[A\big],
\]
και άρα
\[
\mu=\sum_{C\in{\cal R}}\mu\big[C\big]\pi_C
\]
Παρατηρήστε ότι $\mu\big[C\big]\ge 0$ για κάθε $C\in{\cal R}$ και $\sum_{C\in{\cal R}}\mu\big[C\big]=\mu\big[\bigcup_{C\in{\cal R}}C\big] = 1.$ Επομένως έχουμε γράψει το $\mu$ σαν ένα κυρτό συνδυασμό των $\pi_C$ και άρα $\IP\subset co\{\pi_{C}: {C}\in{\cal R}\}$.\CQFD
\section{Παραδείγματα}
Στην προηγούμενη παράγραφο μελετήσαμε την δομή των αναλλοίωτων κατανομών μιας μαρκοβιανής αλυσίδας. Είδαμε ότι για κάθε γνησίως επαναληπτική κλάση της $C$ υπάρχει μια μοναδική αναλλοίωτη κατανομή $\pi_C$ της αλυσίδας που στηρίζεται στην $C$ (δηλαδή $x\notin C\Rightarrow \pi_C(x)=0$) και ότι κάθε αναλλοίωτη κατανομή της αλυσίδας μπορεί να γραφτεί σαν ένας κυρτός συνδυασμός των κατανομών $\pi_C$. Είδαμε όμως και αρκετούς τρόπους για να χαρακτηρίσουμε τις $\pi_C$. Έτσι, αν έχουμε μια μη υποβιβάσιμη γνησίως επαναληπτική μαρκοβιανή αλυσίδα $\xn$ με πίνακα πιθανοτήτων μετάβασης $P$ (όπως είναι οποιαδήποτε μαρκοβιανή αλυσίδα περιορισμένη σε μια γνησίως επαναληπτική της κλάση) έχουμε τους ακόλουθους χαρακτηρισμούς για την μοναδική αναλλοίωτη κατανομή της $\pi$.
\begin{enumerate}
\item
Η $\pi$ είναι λύση του προβλήματος
\[
\begin{cases} &\pi=\pi P\\&\sum_{x\in\X}\pi(x)=1\end{cases}
\]
\item Για κάθε $x\in\X$, αν $T_x^+=\inf\{k>0: X_k=x\}$ έχουμε
\[
\pi(x)=\frac{1}{\Ex{T_x^+}}.
\]
\item
Για κάθε $x,y\in\X$ έχουμε
\[
\pi(y)=\pi(x)\ \E_x\Big[\sum_{k=1}^{T_x^+}\mathbbm{1}\{X_k=y\}\Big].
\]
\end{enumerate}
Μπορεί κανείς να χρησιμοποιήσει έναν τρόπο για να υπολογίσει την αναλλοίωτη κατανομή της αλυσίδας και να πάρει από τους άλλους τρόπους  ενδεχομένως χρήσιμες πληροφορίες.
\begin{example}
Ένα έντομο κινείται στις κορυφές $V$ ενός κανονικού $\nu$-γώνου. Σε κάθε βήμα του μετακινείται σε μια από τις δύο γειτονικές κορυφές, με πιθανότητα $p\in(0,1)$ κατά την φορά των δεικτών του ρολογιού και με πιθανότητα $1-p$ αντίστροφα από τους δείκτες του ρολογιού. Ποιος είναι ο αναμενόμενος αριθμός βημάτων μέχρι να επιστρέψει στην αρχική του θέση?\\
\ \\
Η αλυσίδα που καταγράφει την θέση του εντόμου είναι μη υποβιβάσιμη, αφού το έντομο μπορεί να επισκεφτεί όλες τις καταστάσεις και να επιστρέψει στην αρχική του κατάσταση κάνοντας $\nu$ βήματα κατά την φορά των δεικτών του ρολογιού, ενδεχόμενο το οποίο έχει πιθανότητα $p^\nu>0$. Εφόσον $|V|<+\infty$ η αλυσίδα θα είναι γνησίως επαναληπτική και άρα θα έχει μοναδική αναλλοίωτη κατανομή $\pi$. Στο συγκεκριμένο παράδειγμα δεν είναι δύσκολο να μαντέψει κανείς ότι λόγω συμμετρίας η μοναδική αναλλοίωτη κατανομή θα είναι η ομοιόμορφη κατανομή στις κορυφές του $\nu$-γώνου
\[
\pi(x)=\frac{1}{\nu}\quad\text{για κάθε }x\in V.
\]
Πράγματι, για κάθε $x\in V$
\[
\sum_{y\in V}\pi(y)p(y,x)= \sum_{y\in V}\frac{1}{\nu}p(y,x)=\frac{1}{\nu}\big(p+(1-p)\big)=\frac{1}{\nu}=\pi(x).
\]
Επομένως
\[
\Ex{T_x^+}=\frac{1}{\pi(x)}=\nu.
\]
\CQFD\\
Το προηγούμενο παράδειγμα μπορεί να γενικευτεί κατά τον ακόλουθο τρόπο. Θα λέμε ότι ένας στοχαστικός πίνακας $P$ είναι {\em διπλά στοχαστικός} αν $\sum_{x\in\X}p(x,y)=1$ για κάθε $y\in\X$. Έτσι σε έναν διπλά στοχαστικό πίνακα και το άθροισμα των στοιχείων του κατά στήλη είναι ίσο με 1. Παρατηρήστε ότι ένας συμμετρικός πίνακας πιθανοτήτων μετάβασης είναι πάντα διπλά στοχαστικός.
\begin{example}
Μια μη υποβιβάσιμη μαρκοβιανή αλυσίδα που κινείται σε έναν πεπερασμένο χώρο καταστάσεων $\X$ και έχει διπλά στοχαστικό πίνακα πιθανοτήτων μετάβασης έχει μοναδική αναλλοίωτη κατανομή την ομοιόμορφη κατανομή στον $\X$.\\
\ \\
Από το Θεώρημα \ref{uniqueinv}, η αλυσίδα έχει μοναδική αναλλοίωτη κατανομή. Αρκεί λοιπόν να επαληθεύσουμε ότι η ομοιόμορφη κατανομή $\pi:\X\to[0,1]$ με $\pi(x)=\frac{1}{|\X|}$ είναι αναλλοίωτη. Πράγματι, για κάθε $x\in\X$ έχουμε
\[
\sum_{y\in\X} \pi(y)p(y,x)=\frac{1}{|\X|}\sum_{y\in\X}p(y,x)=\frac{1}{|\X|}=\pi(x),
\]
όπου η δεύτερη ισότητα προκύπτει επειδή οπίνακας πιθανοτήτων μετάβασης είναι διπλά στοχαστικός. Επίσης,
\[
\sum_{x\in\X}\pi(x)=\sum_{x\in\X}\frac{1}{|\X|}=\frac{1}{|\X|}|\X|=1,
\]
και άρα $\pi\in\IP$.\CQFD
\end{example}
\end{example}
\begin{example}
Σ' ένα ράφι της βιβλιοθήκης σας υπάρχουν τρία βιβλία: \en{Algebra, Basic Topology, Calculus}, που θα συμβολίζουμε με \en{A,B,C} για συντομία. Κάθε πρωί παίρνετε τυχαία ένα βιβλίο από τη θέση του, με πιθανότητα $p,q,r$ αντίστοιχα. Υποθέτουμε $p,q,r>0$ με $p+q+r=1$. Όταν τελειώνετε το διάβασμά σας για την ημέρα το ξαναβάζετε στο ράφι στην αριστερότερη θέση. Η διάταξη των βιβλίων είναι μια μαρκοβιανή αλυσίδα στο χώρο $\X$ των μεταθέσεων των συμβόλων $\{A,B,C\}$. Αν κάποια στιγμή τα βιβλία είναι τοποθετημένα με αλφαβητική σειρά βρείτε τον αναμενόμενο αριθμό ημερών μέχρι τα βιβλία να ξαναβρεθούν τοποθετημένα με αλφαβητική σειρά. Πόσες κατά μέση τιμή ημέρες θα διαβάσετε το βιβλίο \en{Calculus} ενδιάμεσα σε αυτές τις στιγμές.\\
\ \\ 
Ας απαριθμήσουμε τις δυνατές καταστάσεις με την εξής σειρά $$\X=\{ABC,CAB,BCA,BAC,ACB,CBA\}.$$ Ο πίνακας πιθανοτήτων μετάβασης της αλυσίδας είναι ο
\[
P=\left(\begin{array}{cccccc}p&r&0&q&0&0\\0&r&q&0&p&0\\p&0&q&0&0&r\\p&0&0&q&0&r\\0&r&0&q&p&0\\0&0&q&0&p&r\end{array}\right).
\]
Το ότι η αλυσίδα είναι μη υποβιβάσιμη είναι διαισθητικά φανερό. Μπορείτε να δείτε ότι όποια κι αν είναι η αρχική της κατάσταση, αν επιλέξετε τις δυο πρώτες μέρες το δεξιότερο βιβλίο, την τρίτη μέρα το μεσαίο βιβλίο, και τις δυο επόμενες πάλι το δεξιότερο βιβλίο (ενδεχόμενο το οποίο έχει θετική πιθανότητα) τότε η διάταξη των βιβλίων στο ράφι θα έχει περάσει από όλες τις δυνατές καταστάσεις της. Εφόσον ο χώρος καταστάσεων είναι πεπερασμένος όλες οι καταστάσεις θα είναι γνησίως επαναληπτικές. Για να βρούμε την μοναδική αναλλοίωτη κατανομή $\pi$ λύνουμε το ομογενές σύστημα εξισώσεων $\pi=\pi P$. Ας δούμε τις εξισώσεις που αφορούν σε καταστάσεις με το $A$ ως αριστερότερο βιβλίο:
\begin{align}
\pi(ABC)&=p\pi(ABC)+p\pi(BAC)+p\pi(BCA)\label{bc}\\
%\Leftrightarrow \pi(ABC)=\frac{p}{1-p}\big(\pi(BAC)+\pi(BCA)\big),
\pi(ACB)&=p\pi(ACB)+p\pi(CAB)+p\pi(CBA).\label{cb}
\end{align}
Αν $S_A=\{ABC,ACB\},$  προσθέτοντας κατά μέλη βρίσκουμε $\pi(S_A)=p\sum_{x\in\X}\pi(x)=p.$
Όμοια, αν $\ S_B=\{BAC,BCA\}$ και $\ S_C=\{CAB,CBA\}$ τότε $\pi(S_B)=q,\ \pi(S_C)=r$. Από τις (\ref{bc}), (\ref{cb}) παίρνουμε τελικά ότι 
\begin{equation}
\pi(ABC)=\frac{p}{1-p} \pi(S_B)=\frac{pq}{1-p} \qquad\text{και}\qquad \pi(ACB)=\frac{p}{1-p}\pi(S_C)=\frac{pr}{1-p}.
\label{A*}
\end{equation}
Οι πιθανότητες των άλλων καταστάσεων βρίσκονται με ανάλογο τρόπο, οπότε τελικά
\[
\pi=(\frac{pq}{1-p}, \frac{rp}{1-r}, \frac{qr}{1-q}, \frac{qp}{1-q}, \frac{pr}{1-p}, \frac{rq}{1-r}).
\]
Έχοντας βρει την αναλλοίωτη κατανομή της αλυσίδας μπορούμε εύκολα να απαντήσουμε τα υπόλοιπα ερωτήματα. Έτσι, αν $T_{ABC}^+=\inf\{k>0: X_k=ABC\}$ τότε
\[
\E\big[T_{ABC}^+\,|\,X_0=ABC\big]=\frac{1}{\pi(ABC)}=\frac{1-p}{pq}.
\]
Κάθε φορά που διαβάζετε το βιβλίο \en{Calculus} το τοποθετείτε αριστερά οπότε η αλυσίδα περνά από μια από της καταστάσεις του $S_C$. Έτσι,
\[
\E\Big[\sum_{k=1}^{T_{ABC}^+}\mathbbm{1}\big\{X_k\in S_C\big\}\,\Big|\,X_0=ABC\Big]=\frac{\pi[S_C]}{\pi(ABC)}=\frac{(1-p)r}{pq}.\qquad\CQFD
\]
\end{example}
\section{Ασκήσεις}
\begin{exercise}
H $\{X_n\}_{n\in\N_0}$ είναι μια μαρκοβιανή αλυσίδα στο χώρο καταστάσεων $\X=\{1,2,3,4\}$ με πίνακα μετάβασης 
\[
P=\left(\begin{array}{cccc} 0&1/2&1/3&1/6\\1/2&0&1/4&1/4\\0&1/2&0&1/2\\1/2&1/3&1/6&0\end{array}\right).
\] 
α) Βρείτε την αναλλοίωτη κατανομή της αλυσίδας.\\
β) Αν $X_0=1$ υπολογίστε τον αναμενόμενο χρόνο πρώτης επιστροφής $T_1^+=\inf\{k>0:\ X_k=1\}$ στην κατάσταση 1.\\
γ) Υπολογίστε τον αναμενόμενο αριθμό επισκέψεων στην κατάσταση 3 μέχρι τη συμπλήρωση 93 επιστροφών στην κατάσταση 1.
\end{exercise}
\begin{exercise}
Στο διπλανό σχήμα φαίνεται η κάτοψη ενός σπιτιού με 5 δωμάτια: κουζίνα (Κ), βιβλιοθήκη (Β), σαλόνι (Σ), υπνοδωμάτιο (Υ), και μπάνιο (Μ), και οι πόρτες που τα συνδέουν. \\[1mm]
\begin{minipage}[b]{0.72\linewidth}
Ένα έντομο που ζει στο σπίτι, κάθε βράδυ διασχίζει τυχαία μια από τις πόρτες του δωματίου που βρίσκεται, και παραμένει στο δωμάτιο που οδηγεί η πόρτα μέχρι το επόμενο βράδυ. Αρχικά το έντομο βρίσκεται στο μπάνιο.\\
α) Αν $\{X_n:\ n=0,1,2,\ldots\}$ είναι η μαρκοβιανή αλυσίδα στο χώρο καταστάσεων \{Κ,Β,Σ,Υ,Μ\} που περιγράφει τη θέση του εντόμου κάθε μέρα, βρείτε τον πίνακα πιθανοτήτων μετάβασης ${P}$ της $\{X_n\}$.\\
β) Βρείτε όλες τις αναλλοίωτες κατανομές της $\{X_n\}$.\\
γ) Υπολογίστε τον αναμενόμενο αριθμό ημερών μέχρι την πρώτη επιστροφή του εντόμου στο μπάνιο.\\
\end{minipage}
\begin{minipage}[b]{0.26\linewidth}
\includegraphics[width=0.95\linewidth]{Maze}
\end{minipage}\\
δ) Υπολογίστε τον αναμενόμενο αριθμό ημερών που θα περάσει το έντομο στο σαλόνι μέχρι την πρώτη του επιστροφή στο μπάνιο.\\
ε) Αν ένα άλλο έντομο αρχικά βρίσκεται στην κουζίνα και μετακινείται κάθε μέρα όπως το πρώτο, ποια είναι η πιθανότητα κάποια μέρα τα δύο έντομα να βρεθούν στο ίδιο δωμάτιο? 
\end{exercise}
\begin{exercise}
Ένας παντοπώλης εφοδιάζεται κάθε πρωί με ένα πακέτο μπισκότα. Έχει παρατηρήσει ότι η ημερήσια ζήτηση είναι μια τυχαία μεταβλητή $X$ με κατανομή $\PP{X=0}=\frac{1}{4}$, $\PP{X=1}=\frac{1}{2}$, $\PP{X=2}=\frac{1}{6}$, $\PP{X=3}=\frac{1}{12}$. Περιγράψτε την ποσότητα από μπισκότα που έχει στο παντοπωλείο κάθε βράδυ σαν μια μαρκοβιανή αλυσίδα και βρείτε την αναλλοίωτη κατανομή της. Αν χτες το βράδυ δεν είχε μείνει κανένα πακέτο μπισκότα στο παντοπωλείο, ποιος είναι ο αναμενόμενος αριθμός ημερών μέχρι την επόμενη φορά που το παντοπωλείο θα μείνει χωρίς μπισκότα?
\end{exercise}
\begin{exercise}
Μια μαρκοβιανή αλυσίδα στον $\X=\N_0$ μετατοπίζεται ένα βήμα προς τα αριστερά όταν δεν βρίσκεται στο 0, και όταν φτάσει στο 0 κάνει ένα άλμα που ακολουθεί γεωμετρική κατανομή με παράμετρο $q\ (0<q<1)$. Υπολογίστε την αναλλοίωτη κατανομή της με τρεις διαφορετικούς τρόπους.
\end{exercise}
\begin{exercise}
Μια μαρκοβιανή αλυσίδα στον $\X=\{0,1,2,\ldots\}$ έχει πιθανότητες μετάβασης $p(k,k+1)=p<1,\ p(k,0)=1-p,\ \forall k\in\X$.
Βρείτε την αναλλοίωτη κατανομή της. Ποια είναι η αναμενόμενη τιμή του χρόνου που μεσολαβεί ανάμεσα σε δύο διαδοχικές επισκέψεις στο 3? Ποιος είναι ο αναμενόμενος αριθμός επισκέψεων στο 0 ανάμεσα σε δύο διαδοχικές επισκέψεις στο 3?
\end{exercise}
\begin{exercise}
Ο  κύριος Χ αντιμετωπίζει ένα σοβαρό πρόβλημα μνήμης. Κάθε νύχτα ξεχνά ένα μέρος από τα πρόσωπα που γνωρίζει. Συγκεκριμένα, αν θυμάται $k$ πρόσωπα πριν πέσει για ύπνο, το πλήθος των προσώπων που εξακολουθεί να θυμάται μόλις ξυπνήσει μπορεί να είναι $0,1,2,\ldots,k$, καθένα με πιθανότητα $1/(k+1)$. Ο γιατρός που τον παρακολουθεί του μαθαίνει κάθε μέρα ένα πρόσωπο, διαφορετικό από αυτά που θυμάται. Αν $X_n$ είναι το πλήθος των προσώπων που ο κύριος Χ θυμάται το βράδυ της $n$-στης ημέρας\\[2mm]
α) Βρείτε τις πιθανότητες μετάβασης $p(j,k),\ j,k\in\N$ της αλυσίδας $X_n$.\\
β) Δείξτε ότι η μοναδική αναλλοίωτη κατανομή της $\{X_n\}$ είναι η $\pi:\N\to[0,1]$ με $\pi(k)=\frac{1}{e(k-1)!}$.\\
γ) Αν κάποιο βράδυ ο κύριος Χ θυμάται 3 πρόσωπα πριν πέσει για ύπνος ποιος είναι ο αναμενόμενος χρόνος που θα μεσολαβήσει μέχρι το επόμενο βράδυ που θα θυμάται πάλι 3 πρόσωπα? 
\end{exercise}
\begin{exercise}
Αν ${\cal R}\neq\emptyset$ είναι το σύνολο των γνησίως επαναληπτικών κλάσεων μιας αλυσίδας $\{X_n\}_n$ και $\pi\in\IP$,  δείξτε ότι υπάρχει μόνο ένας τρόπος να γράψουμε την $\pi$ ως
\[
\pi=\sum_{C\in{\cal R}} \alpha(C)\pi_C.
\]
\end{exercise}
\section{Αριθμητικά πειράματα}
\begin{exercise}
Σ' αυτήν την άσκηση θα δούμε πώς μπορούμε να κάνουμε γραφικές παραστάσεις με την \en{Python}. Κατεβάστε το πρόγραμμα 
\en{{\tt example\_plot.py}} και αποθηκεύστε το στον κατάλογο που θα δουλέψετε. Τρέξτε το πρόγραμμα. Το πρόγραμμα τυπώνει 
την γραφική παράσταση της συνάρτησης $x\mapsto 32x^3$ στο διάστημα (0,6) σε κανονική και λογαριθμική (με βάση το 2) κλίμακα.\\
α) Γιατί σε λογαριθμική κλίμακα βλέπουμε μια ευθεία?\\
β) Εκτιμήστε γραφικά την κλίση της ευθείας και το σημείο που τέμνει τον άξονα $y'y$.\\[2mm]
Για τα επόμενα 2 ερωτήματα ίσως σας βοηθήσει να έχετε ανοίξει τον κώδικα με έναν επεξεργαστή κειμένου σε ένα τερματικό, και να εκτελείτε το πρόγραμμα από ένα άλλο τερματικό.\\[2mm]
γ) Αλλάξτε την συνάρτηση σε $x\mapsto 8x^3$ και ξανατρέξτε το πρόγραμμα. Πώς αλλάζει το διάγραμμα σε λογαριθμική κλίμακα?\\
δ) Αλλάξτε την συνάρτηση σε $x\mapsto 8x^2$ και ξανατρέξτε το πρόγραμμα. Πώς αλλάζει το διάγραμμα σε λογαριθμική κλίμακα?\\[2mm]
Κλείστε τώρα το παράθυρο γραφικών και αλλάξτε το πρόγραμμα ώστε να ξαναπάρετε την γραφική παράσταση της $x\mapsto 32x^3$.
Αφαιρέστε το σύμβολο $\#$ που καθιστά σχoλιασμό τις δύο γραμμές στο τέλος του προγράμματος
\selectlanguage{english}
\begin{verbatim} a,b = np.polyfit(newx,newy,1) \end{verbatim} 
\begin{verbatim} print "The fitted line is y=%.2f*x+%.2f " % (a,b) \end{verbatim} 
\selectlanguage{greek}
H πρώτη υπολογίζει τους συντελεστές της ευθείας $y=ax+b$ που προσαρμόζεται καλύτερα 
στα σημεία \en{{\tt (newx,newy)}}. Η παράμετρος 1 δηλώνει ότι θέλουμε να προσαρμόσουμε ένα 
πολυώνυμο βαθμού 1, δηλαδή μια ευθεία. Η δεύτερη γραμμή απλά τυπώνει το αποτέλεσμα (με δύο δεκαδικά ψηφία) για τον χρήστη. Ξανατρέξτε το πρόγραμμα.\\[2mm]
ε) Συμφωνεί το αποτέλεσμα για τα $a,b$ με αυτό που βρήκατε στο ερώτημα (β)?
\end{exercise}
\begin{exercise}
Κατεβάστε το πρόγραμμα \en{{\tt variance.py}} και αποθηκεύστε το στον κατάλογο που θα δουλέψετε. \\[2mm]
Το πρόγραμμα προσομοιώνει μια αλυσίδα στον χώρο καταστάσεων $\X=\{1,2,3,4,5\}$, και υπολογίζει με την μέθοδο \en{Monte Carlo} τον αναμενόμενο χρόνο επιστροφής στην κατάσταση 1, $\EE{T_1^+\,|\,X_0=1}$, όπου
\[
T_1^+=\inf\{k>0: X_k=1\}.
\]
H εκτίμηση για την $\EE{T_1^+\,|\,X_0=1}$ λαμβάνεται προσομοιώνοντας την αλυσίδα $N$ φορές, παίρνοντας $N$ ανεξάρτητα δείγματα $t_1,\ldots,t_N$ του χρόνου επιστροφής στο 1, και παίρνοντας τον μέσο όρο αυτών των δειγμάτων.
O νόμος των μεγάλων αριθμών εγγυάται ότι ο μέσος όρος αυτών των $N$ ανεξάρτητων δειγμάτων της τυχαίας μεταβλητής $T_1^+$ είναι για αρκετά μεγάλο $N$ κοντά στην $\EE{T_1^+\,|\,X_0=1}$ με μεγάλη πιθανότητα. Θα καλούμε την
\[
Ε_N=\frac{t_1+t_2+\cdots+t_N}{N}
\]
εκτιμήτρια \en{Monte Carlo} της αναμενόμενης τιμής $\EE{T_1^+\,|\,X_0=1}$. Φυσικά η $E_N$ είναι μια τυχαία μεταβλητή και αν ξανακάνουμε το πείραμα θα πάρουμε μια διαφορετική εκτίμηση. \\[2mm]
α) Τρέξτε το πρόγραμμα μερικές φορές και δείτε πόσο διαφέρουν οι εκτιμήσεις που παίρνουμε κάθε φορά για την $\EE{T_1^+\,|\,X_0=1}$. Επαναλάβετε για $N=2^6,2^7,\ldots,2^{12}$. Φαίνεται να διαφέρουν λιγότερο οι διαφορετικές εκτιμήσεις καθώς μεγαλώνει το $N$?\\[2mm]
Σκοπός αυτής της άσκησης είναι να βρούμε υπολογιστικά πώς επηρεάζεται η διασπορά της εκτιμήτριας $E_N$ από το πλήθος των επαναλήψεων $N$.\\[2mm]
β) Φτιάξτε έναν βρόχο που θα κάνει $M=30$ εκτιμήσεις της $\EE{T_1^+\,|\,X_0=1}$ για κάθε δεδομένη τιμή του $N$ και αποθηκεύστε αυτές τις $Μ$ εκτιμήσεις στην λίστα \en{mcestimates}.\\[2mm]
γ) Υπολογίστε την δειγματική μέση τιμή και την δειγματική διασπορά αυτών των εκτιμήσεων αφαιρώντας τον σχολιασμό από τις εντολές\\[1mm]
\en{{\tt sample\_mean = float( sum(mcestimates) ) / M}}\\[0.5mm]
\en{{\tt squared\_distance\_from\_mean = [ (e - sample\_mean)**2 for e in mcestimates ]}}\\[0.5mm]
\en{{\tt sample\_variance= float(sum ( squared\_distance\_from\_mean )) / (M-1)}}\\[0.5mm]
%\selectlanguage{greek}
που βρίσκονται στο τέλος του προγράμματος.\\[2mm]
δ) Φτιάξτε έναν βρόχο που κάνει τον παραπάνω υπολογισμό για $N=2^6,2^7,\ldots,2^{14}$ και παραστήστε γραφικά πώς εξαρτάται η δειγματική μέση τιμή και η δειγματική τυπική απόκλιση από το $N$.\\[2mm]
ε) Υπολογίστε θεωρητικά την $\EE{T_1^+\,|\,X_0=1}$. Συμφωνεί το αριθμητικό αποτέλεσμα που βρήκατε με την θεωρητική τιμή?\\[2mm]
στ) Σχεδιάστε σε λογαριθμική κλίμακα πώς εξαρτάται η δειγματική τυπική απόκλιση της εκτιμήτριας \en{Monte Carlo} από το $N$. Ποια είναι η κλίση της ευθείας στο λογαριθμικό διάγραμμα? Συμφωνεί αυτό που βρήκατε με το κεντρικό οριακό θεώρημα?
\end{exercise}

\end{document}


